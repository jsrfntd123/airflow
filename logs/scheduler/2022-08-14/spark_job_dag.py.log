[2022-08-14 17:51:26,972] {processor.py:153} INFO - Started process (PID=7160) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:51:26,973] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:51:26,973] {logging_mixin.py:115} INFO - [2022-08-14 17:51:26,973] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:51:27,172] {logging_mixin.py:115} INFO - [2022-08-14 17:51:27,171] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 50, in <module>
    t_check_repo >> t_dummy >> t_git_pull
NameError: name 't_dummy' is not defined
[2022-08-14 17:51:27,173] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:51:27,189] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.220 seconds
[2022-08-14 17:51:58,042] {processor.py:153} INFO - Started process (PID=7237) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:51:58,044] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:51:58,045] {logging_mixin.py:115} INFO - [2022-08-14 17:51:58,045] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:51:58,253] {logging_mixin.py:115} INFO - [2022-08-14 17:51:58,251] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 50, in <module>
    t_check_repo >> t_dummy >> t_git_pull
NameError: name 't_dummy' is not defined
[2022-08-14 17:51:58,254] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:51:58,272] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.234 seconds
[2022-08-14 17:52:28,961] {processor.py:153} INFO - Started process (PID=7314) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:52:28,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:52:28,963] {logging_mixin.py:115} INFO - [2022-08-14 17:52:28,963] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:52:29,187] {logging_mixin.py:115} INFO - [2022-08-14 17:52:29,185] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 50, in <module>
    t_check_repo >> t_dummy >> t_git_pull
NameError: name 't_dummy' is not defined
[2022-08-14 17:52:29,188] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:52:29,207] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.251 seconds
[2022-08-14 17:52:59,796] {processor.py:153} INFO - Started process (PID=7391) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:52:59,798] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:52:59,799] {logging_mixin.py:115} INFO - [2022-08-14 17:52:59,799] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:53:00,011] {logging_mixin.py:115} INFO - [2022-08-14 17:53:00,009] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 50, in <module>
    t_check_repo >> t_dummy >> t_git_pull
NameError: name 't_dummy' is not defined
[2022-08-14 17:53:00,011] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:53:00,029] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.237 seconds
[2022-08-14 17:53:30,269] {processor.py:153} INFO - Started process (PID=7459) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:53:30,270] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:53:30,271] {logging_mixin.py:115} INFO - [2022-08-14 17:53:30,271] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:53:30,507] {logging_mixin.py:115} INFO - [2022-08-14 17:53:30,505] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 50, in <module>
    t_check_repo >> t_dummy >> t_git_pull
NameError: name 't_dummy' is not defined
[2022-08-14 17:53:30,510] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:53:30,532] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.268 seconds
[2022-08-14 17:54:01,024] {processor.py:153} INFO - Started process (PID=7536) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:54:01,026] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:54:01,027] {logging_mixin.py:115} INFO - [2022-08-14 17:54:01,027] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:54:01,239] {logging_mixin.py:115} INFO - [2022-08-14 17:54:01,237] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 50, in <module>
    t_check_repo >> t_dummy >> t_git_pull
NameError: name 't_dummy' is not defined
[2022-08-14 17:54:01,240] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:54:01,258] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.239 seconds
[2022-08-14 17:54:31,685] {processor.py:153} INFO - Started process (PID=7613) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:54:31,687] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:54:31,688] {logging_mixin.py:115} INFO - [2022-08-14 17:54:31,688] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:54:31,898] {logging_mixin.py:115} INFO - [2022-08-14 17:54:31,897] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 50, in <module>
    t_check_repo >> t_dummy >> t_git_pull
NameError: name 't_dummy' is not defined
[2022-08-14 17:54:31,900] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:54:31,916] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.235 seconds
[2022-08-14 17:55:02,223] {processor.py:153} INFO - Started process (PID=7690) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:55:02,224] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:55:02,225] {logging_mixin.py:115} INFO - [2022-08-14 17:55:02,225] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:55:02,447] {logging_mixin.py:115} INFO - [2022-08-14 17:55:02,445] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 50, in <module>
    t_check_repo >> t_dummy >> t_git_pull
NameError: name 't_dummy' is not defined
[2022-08-14 17:55:02,447] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:55:02,464] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.246 seconds
[2022-08-14 17:55:32,704] {processor.py:153} INFO - Started process (PID=7758) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:55:32,706] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:55:32,707] {logging_mixin.py:115} INFO - [2022-08-14 17:55:32,707] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:55:32,916] {logging_mixin.py:115} INFO - [2022-08-14 17:55:32,915] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 50, in <module>
    t_check_repo >> t_dummy >> t_git_pull
NameError: name 't_dummy' is not defined
[2022-08-14 17:55:32,917] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:55:32,933] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.233 seconds
[2022-08-14 17:56:02,992] {processor.py:153} INFO - Started process (PID=7835) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:56:02,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:56:02,994] {logging_mixin.py:115} INFO - [2022-08-14 17:56:02,994] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:56:03,200] {logging_mixin.py:115} INFO - [2022-08-14 17:56:03,199] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 50, in <module>
    t_check_repo >> t_dummy >> t_git_pull
NameError: name 't_dummy' is not defined
[2022-08-14 17:56:03,202] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:56:03,218] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.230 seconds
[2022-08-14 17:56:33,593] {processor.py:153} INFO - Started process (PID=7912) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:56:33,595] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:56:33,596] {logging_mixin.py:115} INFO - [2022-08-14 17:56:33,596] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:56:33,802] {logging_mixin.py:115} INFO - [2022-08-14 17:56:33,801] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 50, in <module>
    t_check_repo >> t_dummy >> t_git_pull
NameError: name 't_dummy' is not defined
[2022-08-14 17:56:33,803] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:56:33,824] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.235 seconds
[2022-08-14 17:57:04,561] {processor.py:153} INFO - Started process (PID=7980) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:57:04,562] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:57:04,563] {logging_mixin.py:115} INFO - [2022-08-14 17:57:04,563] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:57:04,773] {logging_mixin.py:115} INFO - [2022-08-14 17:57:04,772] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 50, in <module>
    t_check_repo >> t_dummy >> t_git_pull
NameError: name 't_dummy' is not defined
[2022-08-14 17:57:04,774] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:57:04,792] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.235 seconds
[2022-08-14 17:57:35,099] {processor.py:153} INFO - Started process (PID=8057) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:57:35,100] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:57:35,101] {logging_mixin.py:115} INFO - [2022-08-14 17:57:35,101] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:57:35,310] {logging_mixin.py:115} INFO - [2022-08-14 17:57:35,308] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 50, in <module>
    t_check_repo >> t_dummy >> t_git_pull
NameError: name 't_dummy' is not defined
[2022-08-14 17:57:35,311] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:57:35,328] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.234 seconds
[2022-08-14 17:58:05,678] {processor.py:153} INFO - Started process (PID=8134) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:58:05,679] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:58:05,681] {logging_mixin.py:115} INFO - [2022-08-14 17:58:05,681] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:58:05,973] {logging_mixin.py:115} INFO - [2022-08-14 17:58:05,972] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 50, in <module>
    t_check_repo >> t_dummy >> t_git_pull
NameError: name 't_dummy' is not defined
[2022-08-14 17:58:05,974] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:58:05,991] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.318 seconds
[2022-08-14 17:58:07,269] {processor.py:153} INFO - Started process (PID=8139) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:58:07,270] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:58:07,271] {logging_mixin.py:115} INFO - [2022-08-14 17:58:07,271] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:58:07,475] {logging_mixin.py:115} INFO - [2022-08-14 17:58:07,473] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 63, in <module>
    network_mode='bridge'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 188, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: docker_command). Invalid arguments were:
**kwargs: {'volumes': ['/home/airflow/simple-app:/simple-app']}
[2022-08-14 17:58:07,476] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:58:07,495] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.250 seconds
[2022-08-14 17:58:10,416] {processor.py:153} INFO - Started process (PID=8156) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:58:10,417] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:58:10,418] {logging_mixin.py:115} INFO - [2022-08-14 17:58:10,418] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:58:10,639] {logging_mixin.py:115} INFO - [2022-08-14 17:58:10,636] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 61, in <module>
    network_mode='bridge'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 188, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: docker_command). Invalid arguments were:
**kwargs: {'volumes': ['/home/airflow/simple-app:/simple-app']}
[2022-08-14 17:58:10,639] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:58:10,655] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.243 seconds
[2022-08-14 17:58:41,326] {processor.py:153} INFO - Started process (PID=8233) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:58:41,328] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:58:41,329] {logging_mixin.py:115} INFO - [2022-08-14 17:58:41,329] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:58:41,536] {logging_mixin.py:115} INFO - [2022-08-14 17:58:41,534] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 61, in <module>
    network_mode='bridge'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 188, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: docker_command). Invalid arguments were:
**kwargs: {'volumes': ['/home/airflow/simple-app:/simple-app']}
[2022-08-14 17:58:41,537] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:58:41,553] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.232 seconds
[2022-08-14 17:59:11,629] {processor.py:153} INFO - Started process (PID=8310) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:59:11,631] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:59:11,632] {logging_mixin.py:115} INFO - [2022-08-14 17:59:11,632] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:59:11,840] {logging_mixin.py:115} INFO - [2022-08-14 17:59:11,839] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 61, in <module>
    network_mode='bridge'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 188, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: docker_command). Invalid arguments were:
**kwargs: {'volumes': ['/home/airflow/simple-app:/simple-app']}
[2022-08-14 17:59:11,841] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:59:11,857] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.231 seconds
[2022-08-14 17:59:36,407] {processor.py:153} INFO - Started process (PID=8358) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:59:36,409] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:59:36,410] {logging_mixin.py:115} INFO - [2022-08-14 17:59:36,410] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:59:36,614] {logging_mixin.py:115} INFO - [2022-08-14 17:59:36,612] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 65, in <module>
    network_mode='bridge'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 188, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: docker_command). Invalid arguments were:
**kwargs: {'volumes': ['/home/airflow/simple-app:/simple-app']}
[2022-08-14 17:59:36,614] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:59:36,633] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.230 seconds
[2022-08-14 17:59:41,132] {processor.py:153} INFO - Started process (PID=8372) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:59:41,133] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 17:59:41,134] {logging_mixin.py:115} INFO - [2022-08-14 17:59:41,134] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:59:41,367] {logging_mixin.py:115} INFO - [2022-08-14 17:59:41,365] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 65, in <module>
    network_mode='bridge'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 188, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: docker_command). Invalid arguments were:
**kwargs: {'volumes': ['/home/airflow/simple-app:/simple-app']}
[2022-08-14 17:59:41,368] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 17:59:41,386] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.257 seconds
[2022-08-14 18:00:11,903] {processor.py:153} INFO - Started process (PID=8448) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:00:11,904] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:00:11,905] {logging_mixin.py:115} INFO - [2022-08-14 18:00:11,905] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:00:12,129] {logging_mixin.py:115} INFO - [2022-08-14 18:00:12,127] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 65, in <module>
    network_mode='bridge'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 188, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: docker_command). Invalid arguments were:
**kwargs: {'volumes': ['/home/airflow/simple-app:/simple-app']}
[2022-08-14 18:00:12,130] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:00:12,148] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.250 seconds
[2022-08-14 18:00:42,225] {processor.py:153} INFO - Started process (PID=8524) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:00:42,226] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:00:42,228] {logging_mixin.py:115} INFO - [2022-08-14 18:00:42,227] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:00:42,438] {logging_mixin.py:115} INFO - [2022-08-14 18:00:42,436] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 65, in <module>
    network_mode='bridge'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 188, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: docker_command). Invalid arguments were:
**kwargs: {'volumes': ['/home/airflow/simple-app:/simple-app']}
[2022-08-14 18:00:42,439] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:00:42,459] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.239 seconds
[2022-08-14 18:01:12,653] {processor.py:153} INFO - Started process (PID=8599) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:01:12,655] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:01:12,656] {logging_mixin.py:115} INFO - [2022-08-14 18:01:12,656] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:01:12,870] {logging_mixin.py:115} INFO - [2022-08-14 18:01:12,868] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 65, in <module>
    network_mode='bridge'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 188, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: docker_command). Invalid arguments were:
**kwargs: {'volumes': ['/home/airflow/simple-app:/simple-app']}
[2022-08-14 18:01:12,871] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:01:12,888] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.238 seconds
[2022-08-14 18:01:43,063] {processor.py:153} INFO - Started process (PID=8667) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:01:43,064] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:01:43,065] {logging_mixin.py:115} INFO - [2022-08-14 18:01:43,065] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:01:43,289] {logging_mixin.py:115} INFO - [2022-08-14 18:01:43,286] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 65, in <module>
    network_mode='bridge'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 188, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: docker_command). Invalid arguments were:
**kwargs: {'volumes': ['/home/airflow/simple-app:/simple-app']}
[2022-08-14 18:01:43,290] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:01:43,309] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.250 seconds
[2022-08-14 18:02:13,627] {processor.py:153} INFO - Started process (PID=8743) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:02:13,628] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:02:13,629] {logging_mixin.py:115} INFO - [2022-08-14 18:02:13,629] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:02:13,846] {logging_mixin.py:115} INFO - [2022-08-14 18:02:13,844] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 65, in <module>
    network_mode='bridge'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 188, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: docker_command). Invalid arguments were:
**kwargs: {'volumes': ['/home/airflow/simple-app:/simple-app']}
[2022-08-14 18:02:13,847] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:02:13,864] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.240 seconds
[2022-08-14 18:02:17,719] {processor.py:153} INFO - Started process (PID=8756) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:02:17,720] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:02:17,720] {logging_mixin.py:115} INFO - [2022-08-14 18:02:17,720] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:02:17,939] {logging_mixin.py:115} INFO - [2022-08-14 18:02:17,935] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:02:17,939] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:02:17,957] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.243 seconds
[2022-08-14 18:02:48,080] {processor.py:153} INFO - Started process (PID=8833) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:02:48,082] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:02:48,083] {logging_mixin.py:115} INFO - [2022-08-14 18:02:48,083] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:02:48,289] {logging_mixin.py:115} INFO - [2022-08-14 18:02:48,287] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:02:48,290] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:02:48,306] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.231 seconds
[2022-08-14 18:03:18,363] {processor.py:153} INFO - Started process (PID=8909) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:03:18,365] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:03:18,366] {logging_mixin.py:115} INFO - [2022-08-14 18:03:18,366] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:03:18,575] {logging_mixin.py:115} INFO - [2022-08-14 18:03:18,573] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:03:18,576] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:03:18,594] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.234 seconds
[2022-08-14 18:03:48,633] {processor.py:153} INFO - Started process (PID=8978) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:03:48,634] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:03:48,635] {logging_mixin.py:115} INFO - [2022-08-14 18:03:48,635] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:03:48,846] {logging_mixin.py:115} INFO - [2022-08-14 18:03:48,844] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:03:48,847] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:03:48,863] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.233 seconds
[2022-08-14 18:04:19,178] {processor.py:153} INFO - Started process (PID=9049) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:04:19,179] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:04:19,181] {logging_mixin.py:115} INFO - [2022-08-14 18:04:19,180] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:04:19,381] {logging_mixin.py:115} INFO - [2022-08-14 18:04:19,379] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:04:19,382] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:04:19,400] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.227 seconds
[2022-08-14 18:04:33,299] {processor.py:153} INFO - Started process (PID=9085) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:04:33,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:04:33,301] {logging_mixin.py:115} INFO - [2022-08-14 18:04:33,301] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:04:33,512] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:04:33,569] {logging_mixin.py:115} INFO - [2022-08-14 18:04:33,569] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:04:33,590] {logging_mixin.py:115} INFO - [2022-08-14 18:04:33,589] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T17:05:00+00:00, run_after=2022-08-14T18:05:00+00:00
[2022-08-14 18:04:33,605] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.310 seconds
[2022-08-14 18:05:03,932] {processor.py:153} INFO - Started process (PID=9162) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:05:03,934] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:05:03,935] {logging_mixin.py:115} INFO - [2022-08-14 18:05:03,935] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:05:04,141] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:05:04,161] {logging_mixin.py:115} INFO - [2022-08-14 18:05:04,161] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:05:04,181] {logging_mixin.py:115} INFO - [2022-08-14 18:05:04,180] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:05:04,190] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.262 seconds
[2022-08-14 18:05:35,089] {processor.py:153} INFO - Started process (PID=9239) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:05:35,091] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:05:35,093] {logging_mixin.py:115} INFO - [2022-08-14 18:05:35,092] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:05:35,297] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:05:35,310] {logging_mixin.py:115} INFO - [2022-08-14 18:05:35,310] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:05:35,332] {logging_mixin.py:115} INFO - [2022-08-14 18:05:35,331] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:05:35,343] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.257 seconds
[2022-08-14 18:06:05,744] {processor.py:153} INFO - Started process (PID=9307) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:05,746] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:06:05,747] {logging_mixin.py:115} INFO - [2022-08-14 18:06:05,747] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:05,948] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:06,010] {logging_mixin.py:115} INFO - [2022-08-14 18:06:06,010] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:06:06,036] {logging_mixin.py:115} INFO - [2022-08-14 18:06:06,036] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:06:06,051] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.311 seconds
[2022-08-14 18:06:29,550] {processor.py:153} INFO - Started process (PID=9384) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:29,551] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:06:29,553] {logging_mixin.py:115} INFO - [2022-08-14 18:06:29,552] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:29,561] {logging_mixin.py:115} INFO - [2022-08-14 18:06:29,560] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 13
    'start_date'            : datetime(2022 1, 3),
                                            ^
SyntaxError: invalid syntax
[2022-08-14 18:06:29,562] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:29,588] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.043 seconds
[2022-08-14 18:06:33,567] {processor.py:153} INFO - Started process (PID=9385) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:33,569] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:06:33,571] {logging_mixin.py:115} INFO - [2022-08-14 18:06:33,571] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:33,774] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:33,787] {logging_mixin.py:115} INFO - [2022-08-14 18:06:33,787] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:06:33,810] {logging_mixin.py:115} INFO - [2022-08-14 18:06:33,810] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:06:33,824] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.261 seconds
[2022-08-14 18:06:39,622] {processor.py:153} INFO - Started process (PID=9393) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:39,623] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:06:39,624] {logging_mixin.py:115} INFO - [2022-08-14 18:06:39,624] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:39,840] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:39,910] {logging_mixin.py:115} INFO - [2022-08-14 18:06:39,910] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:06:39,957] {logging_mixin.py:115} INFO - [2022-08-14 18:06:39,957] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:06:39,981] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.363 seconds
[2022-08-14 18:06:43,992] {processor.py:153} INFO - Started process (PID=9406) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:43,993] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:06:43,994] {logging_mixin.py:115} INFO - [2022-08-14 18:06:43,994] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:44,192] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:44,204] {logging_mixin.py:115} INFO - [2022-08-14 18:06:44,204] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:06:44,224] {logging_mixin.py:115} INFO - [2022-08-14 18:06:44,224] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:06:44,239] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.251 seconds
[2022-08-14 18:06:57,287] {processor.py:153} INFO - Started process (PID=9450) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:57,289] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:06:57,290] {logging_mixin.py:115} INFO - [2022-08-14 18:06:57,290] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:57,511] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:57,524] {logging_mixin.py:115} INFO - [2022-08-14 18:06:57,524] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:06:57,547] {logging_mixin.py:115} INFO - [2022-08-14 18:06:57,547] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:06:57,560] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.277 seconds
[2022-08-14 18:06:58,597] {processor.py:153} INFO - Started process (PID=9454) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:58,598] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:06:58,599] {logging_mixin.py:115} INFO - [2022-08-14 18:06:58,599] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:58,811] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:06:58,826] {logging_mixin.py:115} INFO - [2022-08-14 18:06:58,826] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:06:58,849] {logging_mixin.py:115} INFO - [2022-08-14 18:06:58,849] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:06:58,863] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.270 seconds
[2022-08-14 18:07:29,425] {processor.py:153} INFO - Started process (PID=9534) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:07:29,426] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:07:29,428] {logging_mixin.py:115} INFO - [2022-08-14 18:07:29,428] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:07:29,644] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:07:29,660] {logging_mixin.py:115} INFO - [2022-08-14 18:07:29,660] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:07:29,684] {logging_mixin.py:115} INFO - [2022-08-14 18:07:29,684] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:07:29,699] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.279 seconds
[2022-08-14 18:08:00,183] {processor.py:153} INFO - Started process (PID=9611) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:08:00,185] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:08:00,186] {logging_mixin.py:115} INFO - [2022-08-14 18:08:00,186] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:08:00,393] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:08:00,449] {logging_mixin.py:115} INFO - [2022-08-14 18:08:00,449] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:08:00,466] {logging_mixin.py:115} INFO - [2022-08-14 18:08:00,466] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:08:00,476] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.298 seconds
[2022-08-14 18:08:30,936] {processor.py:153} INFO - Started process (PID=9679) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:08:30,937] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:08:30,938] {logging_mixin.py:115} INFO - [2022-08-14 18:08:30,938] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:08:31,147] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:08:31,168] {logging_mixin.py:115} INFO - [2022-08-14 18:08:31,168] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:08:31,189] {logging_mixin.py:115} INFO - [2022-08-14 18:08:31,189] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:08:31,205] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.273 seconds
[2022-08-14 18:09:01,664] {processor.py:153} INFO - Started process (PID=9756) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:09:01,665] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:09:01,666] {logging_mixin.py:115} INFO - [2022-08-14 18:09:01,666] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:09:01,867] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:09:01,888] {logging_mixin.py:115} INFO - [2022-08-14 18:09:01,888] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:09:01,910] {logging_mixin.py:115} INFO - [2022-08-14 18:09:01,910] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:09:01,921] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.260 seconds
[2022-08-14 18:09:22,483] {processor.py:153} INFO - Started process (PID=9790) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:09:22,484] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:09:22,485] {logging_mixin.py:115} INFO - [2022-08-14 18:09:22,485] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:09:22,668] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:09:22,680] {logging_mixin.py:115} INFO - [2022-08-14 18:09:22,680] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:09:22,698] {logging_mixin.py:115} INFO - [2022-08-14 18:09:22,697] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:09:22,711] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.231 seconds
[2022-08-14 18:09:53,000] {processor.py:153} INFO - Started process (PID=9867) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:09:53,002] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:09:53,003] {logging_mixin.py:115} INFO - [2022-08-14 18:09:53,003] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:09:53,195] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:09:53,248] {logging_mixin.py:115} INFO - [2022-08-14 18:09:53,248] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:09:53,264] {logging_mixin.py:115} INFO - [2022-08-14 18:09:53,264] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:09:53,274] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.278 seconds
[2022-08-14 18:10:23,857] {processor.py:153} INFO - Started process (PID=9935) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:10:23,859] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:10:23,860] {logging_mixin.py:115} INFO - [2022-08-14 18:10:23,860] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:10:24,064] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:10:24,083] {logging_mixin.py:115} INFO - [2022-08-14 18:10:24,083] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:10:24,102] {logging_mixin.py:115} INFO - [2022-08-14 18:10:24,102] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:10:24,113] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.260 seconds
[2022-08-14 18:10:54,184] {processor.py:153} INFO - Started process (PID=10012) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:10:54,185] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:10:54,186] {logging_mixin.py:115} INFO - [2022-08-14 18:10:54,186] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:10:54,398] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:10:54,414] {logging_mixin.py:115} INFO - [2022-08-14 18:10:54,414] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:10:54,440] {logging_mixin.py:115} INFO - [2022-08-14 18:10:54,440] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-14T19:05:00+00:00
[2022-08-14 18:10:54,452] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.272 seconds
[2022-08-14 18:11:16,159] {processor.py:153} INFO - Started process (PID=10068) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:11:16,161] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:11:16,162] {logging_mixin.py:115} INFO - [2022-08-14 18:11:16,162] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:11:16,366] {logging_mixin.py:115} INFO - [2022-08-14 18:11:16,364] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 65, in <module>
    network_mode='bridge'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 188, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: docker_command). Invalid arguments were:
**kwargs: {'volumes': ['/home/airflow/simple-app:/simple-app']}
[2022-08-14 18:11:16,367] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:11:16,386] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.232 seconds
[2022-08-14 18:11:17,960] {processor.py:153} INFO - Started process (PID=10076) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:11:17,962] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:11:17,964] {logging_mixin.py:115} INFO - [2022-08-14 18:11:17,964] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:11:18,268] {logging_mixin.py:115} INFO - [2022-08-14 18:11:18,265] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 65, in <module>
    network_mode='bridge'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 188, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: docker_command). Invalid arguments were:
**kwargs: {'volumes': ['/home/airflow/simple-app:/simple-app']}
[2022-08-14 18:11:18,272] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:11:18,306] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.350 seconds
[2022-08-14 18:11:48,729] {processor.py:153} INFO - Started process (PID=10153) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:11:48,730] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:11:48,731] {logging_mixin.py:115} INFO - [2022-08-14 18:11:48,731] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:11:48,944] {logging_mixin.py:115} INFO - [2022-08-14 18:11:48,942] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 65, in <module>
    network_mode='bridge'
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 188, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 390, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 744, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: docker_command). Invalid arguments were:
**kwargs: {'volumes': ['/home/airflow/simple-app:/simple-app']}
[2022-08-14 18:11:48,945] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:11:48,966] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.242 seconds
[2022-08-14 18:11:58,492] {processor.py:153} INFO - Started process (PID=10168) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:11:58,493] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:11:58,494] {logging_mixin.py:115} INFO - [2022-08-14 18:11:58,494] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:11:58,695] {logging_mixin.py:115} INFO - [2022-08-14 18:11:58,693] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:11:58,695] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:11:58,712] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.223 seconds
[2022-08-14 18:12:28,828] {processor.py:153} INFO - Started process (PID=10245) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:12:28,829] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:12:28,830] {logging_mixin.py:115} INFO - [2022-08-14 18:12:28,830] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:12:29,022] {logging_mixin.py:115} INFO - [2022-08-14 18:12:29,020] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:12:29,023] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:12:29,039] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.215 seconds
[2022-08-14 18:12:59,146] {processor.py:153} INFO - Started process (PID=10313) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:12:59,148] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:12:59,149] {logging_mixin.py:115} INFO - [2022-08-14 18:12:59,149] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:12:59,349] {logging_mixin.py:115} INFO - [2022-08-14 18:12:59,347] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:12:59,350] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:12:59,366] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.224 seconds
[2022-08-14 18:13:29,770] {processor.py:153} INFO - Started process (PID=10390) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:13:29,772] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:13:29,774] {logging_mixin.py:115} INFO - [2022-08-14 18:13:29,773] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:13:29,973] {logging_mixin.py:115} INFO - [2022-08-14 18:13:29,971] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:13:29,974] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:13:29,991] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.228 seconds
[2022-08-14 18:14:00,089] {processor.py:153} INFO - Started process (PID=10467) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:14:00,091] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:14:00,092] {logging_mixin.py:115} INFO - [2022-08-14 18:14:00,092] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:14:00,285] {logging_mixin.py:115} INFO - [2022-08-14 18:14:00,283] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:14:00,286] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:14:00,303] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.218 seconds
[2022-08-14 18:14:31,065] {processor.py:153} INFO - Started process (PID=10535) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:14:31,066] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:14:31,068] {logging_mixin.py:115} INFO - [2022-08-14 18:14:31,068] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:14:31,271] {logging_mixin.py:115} INFO - [2022-08-14 18:14:31,269] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:14:31,273] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:14:31,293] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.231 seconds
[2022-08-14 18:15:01,509] {processor.py:153} INFO - Started process (PID=10612) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:15:01,511] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:15:01,512] {logging_mixin.py:115} INFO - [2022-08-14 18:15:01,512] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:15:01,715] {logging_mixin.py:115} INFO - [2022-08-14 18:15:01,712] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:15:01,715] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:15:01,731] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.226 seconds
[2022-08-14 18:15:31,932] {processor.py:153} INFO - Started process (PID=10689) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:15:31,933] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:15:31,934] {logging_mixin.py:115} INFO - [2022-08-14 18:15:31,934] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:15:32,116] {logging_mixin.py:115} INFO - [2022-08-14 18:15:32,114] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:15:32,116] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:15:32,133] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.204 seconds
[2022-08-14 18:15:47,507] {processor.py:153} INFO - Started process (PID=10735) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:15:47,508] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:15:47,510] {logging_mixin.py:115} INFO - [2022-08-14 18:15:47,509] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:15:47,706] {logging_mixin.py:115} INFO - [2022-08-14 18:15:47,704] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:15:47,707] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:15:47,723] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.219 seconds
[2022-08-14 18:16:18,678] {processor.py:153} INFO - Started process (PID=10812) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:16:18,679] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:16:18,680] {logging_mixin.py:115} INFO - [2022-08-14 18:16:18,680] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:16:18,888] {logging_mixin.py:115} INFO - [2022-08-14 18:16:18,886] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:16:18,889] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:16:18,905] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.232 seconds
[2022-08-14 18:16:42,039] {processor.py:153} INFO - Started process (PID=10844) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:16:42,041] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:16:42,042] {logging_mixin.py:115} INFO - [2022-08-14 18:16:42,042] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:16:42,144] {logging_mixin.py:115} INFO - [2022-08-14 18:16:42,142] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:16:42,146] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:16:42,201] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.167 seconds
[2022-08-14 18:16:43,057] {processor.py:153} INFO - Started process (PID=10857) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:16:43,058] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:16:43,059] {logging_mixin.py:115} INFO - [2022-08-14 18:16:43,059] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:16:43,157] {logging_mixin.py:115} INFO - [2022-08-14 18:16:43,155] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:16:43,158] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:16:43,177] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.124 seconds
[2022-08-14 18:17:13,400] {processor.py:153} INFO - Started process (PID=10934) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:17:13,401] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:17:13,402] {logging_mixin.py:115} INFO - [2022-08-14 18:17:13,402] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:17:13,493] {logging_mixin.py:115} INFO - [2022-08-14 18:17:13,491] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:17:13,493] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:17:13,515] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.120 seconds
[2022-08-14 18:17:18,044] {processor.py:153} INFO - Started process (PID=10954) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:17:18,046] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:17:18,047] {logging_mixin.py:115} INFO - [2022-08-14 18:17:18,047] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:17:18,161] {logging_mixin.py:115} INFO - [2022-08-14 18:17:18,158] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:17:18,162] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:17:18,189] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.150 seconds
[2022-08-14 18:17:30,329] {processor.py:153} INFO - Started process (PID=10984) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:17:30,330] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:17:30,331] {logging_mixin.py:115} INFO - [2022-08-14 18:17:30,331] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:17:30,414] {logging_mixin.py:115} INFO - [2022-08-14 18:17:30,410] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:17:30,415] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:17:30,435] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.110 seconds
[2022-08-14 18:17:37,336] {processor.py:153} INFO - Started process (PID=10994) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:17:37,337] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:17:37,338] {logging_mixin.py:115} INFO - [2022-08-14 18:17:37,338] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:17:37,420] {logging_mixin.py:115} INFO - [2022-08-14 18:17:37,417] {dagbag.py:320} ERROR - Failed to import: /opt/airflow/dags/spark_job_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 317, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_dag.py", line 71, in <module>
    t_git_pull >> t_docker
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 80, in __rshift__
    self.set_downstream(other)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 233, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskmixin.py", line 214, in _set_relatives
    dag.add_task(task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 2130, in add_task
    raise AirflowException("DAG is missing the start_date parameter")
airflow.exceptions.AirflowException: DAG is missing the start_date parameter
[2022-08-14 18:17:37,422] {processor.py:653} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:17:37,441] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.109 seconds
[2022-08-14 18:17:45,854] {processor.py:153} INFO - Started process (PID=11021) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:17:45,855] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:17:45,856] {logging_mixin.py:115} INFO - [2022-08-14 18:17:45,856] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:17:45,955] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:17:46,032] {logging_mixin.py:115} INFO - [2022-08-14 18:17:46,032] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:17:46,053] {logging_mixin.py:115} INFO - [2022-08-14 18:17:46,053] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-15T18:05:00+00:00
[2022-08-14 18:17:46,070] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.220 seconds
[2022-08-14 18:18:16,245] {processor.py:153} INFO - Started process (PID=11098) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:18:16,246] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:18:16,247] {logging_mixin.py:115} INFO - [2022-08-14 18:18:16,247] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:18:16,327] {processor.py:651} INFO - DAG(s) dict_keys(['docker_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:18:16,356] {logging_mixin.py:115} INFO - [2022-08-14 18:18:16,356] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:18:16,383] {logging_mixin.py:115} INFO - [2022-08-14 18:18:16,383] {dag.py:2919} INFO - Setting next_dagrun for docker_dag to 2022-08-14T18:05:00+00:00, run_after=2022-08-15T18:05:00+00:00
[2022-08-14 18:18:16,398] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.157 seconds
[2022-08-14 18:18:39,522] {processor.py:153} INFO - Started process (PID=11149) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:18:39,528] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:18:39,529] {logging_mixin.py:115} INFO - [2022-08-14 18:18:39,529] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:18:39,611] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:18:39,696] {logging_mixin.py:115} INFO - [2022-08-14 18:18:39,696] {manager.py:508} INFO - Created Permission View: can edit on DAG:spark_job_dag
[2022-08-14 18:18:39,710] {logging_mixin.py:115} INFO - [2022-08-14 18:18:39,710] {manager.py:508} INFO - Created Permission View: can read on DAG:spark_job_dag
[2022-08-14 18:18:39,717] {logging_mixin.py:115} INFO - [2022-08-14 18:18:39,717] {manager.py:508} INFO - Created Permission View: can delete on DAG:spark_job_dag
[2022-08-14 18:18:39,718] {logging_mixin.py:115} INFO - [2022-08-14 18:18:39,718] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:18:39,727] {logging_mixin.py:115} INFO - [2022-08-14 18:18:39,727] {dag.py:2390} INFO - Creating ORM DAG for spark_job_dag
[2022-08-14 18:18:39,739] {logging_mixin.py:115} INFO - [2022-08-14 18:18:39,739] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-13T18:18:39.739604+00:00, run_after=2022-08-14T18:18:39.739604+00:00
[2022-08-14 18:18:39,752] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.234 seconds
[2022-08-14 18:19:09,826] {processor.py:153} INFO - Started process (PID=11217) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:19:09,827] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:19:09,828] {logging_mixin.py:115} INFO - [2022-08-14 18:19:09,828] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:19:09,905] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:19:09,930] {logging_mixin.py:115} INFO - [2022-08-14 18:19:09,930] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:19:09,951] {logging_mixin.py:115} INFO - [2022-08-14 18:19:09,951] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-13T18:19:09.951551+00:00, run_after=2022-08-14T18:19:09.951551+00:00
[2022-08-14 18:19:09,961] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.140 seconds
[2022-08-14 18:19:40,409] {processor.py:153} INFO - Started process (PID=11294) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:19:40,411] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:19:40,412] {logging_mixin.py:115} INFO - [2022-08-14 18:19:40,412] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:19:40,482] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:19:40,506] {logging_mixin.py:115} INFO - [2022-08-14 18:19:40,506] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:19:40,528] {logging_mixin.py:115} INFO - [2022-08-14 18:19:40,528] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:19:40,538] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.133 seconds
[2022-08-14 18:20:10,715] {processor.py:153} INFO - Started process (PID=11371) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:20:10,716] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:20:10,718] {logging_mixin.py:115} INFO - [2022-08-14 18:20:10,717] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:20:10,798] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:20:10,825] {logging_mixin.py:115} INFO - [2022-08-14 18:20:10,825] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:20:10,851] {logging_mixin.py:115} INFO - [2022-08-14 18:20:10,851] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:20:10,868] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.159 seconds
[2022-08-14 18:20:41,225] {processor.py:153} INFO - Started process (PID=11439) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:20:41,227] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:20:41,228] {logging_mixin.py:115} INFO - [2022-08-14 18:20:41,228] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:20:41,305] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:20:41,332] {logging_mixin.py:115} INFO - [2022-08-14 18:20:41,332] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:20:41,355] {logging_mixin.py:115} INFO - [2022-08-14 18:20:41,355] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:20:41,365] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.144 seconds
[2022-08-14 18:21:11,702] {processor.py:153} INFO - Started process (PID=11516) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:21:11,703] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:21:11,704] {logging_mixin.py:115} INFO - [2022-08-14 18:21:11,704] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:21:11,772] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:21:11,800] {logging_mixin.py:115} INFO - [2022-08-14 18:21:11,800] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:21:11,822] {logging_mixin.py:115} INFO - [2022-08-14 18:21:11,822] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:21:11,833] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.134 seconds
[2022-08-14 18:21:42,254] {processor.py:153} INFO - Started process (PID=11593) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:21:42,255] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:21:42,256] {logging_mixin.py:115} INFO - [2022-08-14 18:21:42,256] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:21:42,331] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:21:42,358] {logging_mixin.py:115} INFO - [2022-08-14 18:21:42,358] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:21:42,383] {logging_mixin.py:115} INFO - [2022-08-14 18:21:42,383] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:21:42,393] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.144 seconds
[2022-08-14 18:22:12,540] {processor.py:153} INFO - Started process (PID=11670) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:22:12,541] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:22:12,542] {logging_mixin.py:115} INFO - [2022-08-14 18:22:12,542] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:22:12,619] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:22:12,646] {logging_mixin.py:115} INFO - [2022-08-14 18:22:12,646] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:22:12,668] {logging_mixin.py:115} INFO - [2022-08-14 18:22:12,668] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:22:12,679] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.144 seconds
[2022-08-14 18:22:43,010] {processor.py:153} INFO - Started process (PID=11738) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:22:43,013] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:22:43,014] {logging_mixin.py:115} INFO - [2022-08-14 18:22:43,014] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:22:43,108] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:22:43,138] {logging_mixin.py:115} INFO - [2022-08-14 18:22:43,138] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:22:43,167] {logging_mixin.py:115} INFO - [2022-08-14 18:22:43,167] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:22:43,182] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.176 seconds
[2022-08-14 18:23:13,348] {processor.py:153} INFO - Started process (PID=11815) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:23:13,349] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:23:13,350] {logging_mixin.py:115} INFO - [2022-08-14 18:23:13,350] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:23:13,435] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:23:13,465] {logging_mixin.py:115} INFO - [2022-08-14 18:23:13,465] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:23:13,489] {logging_mixin.py:115} INFO - [2022-08-14 18:23:13,488] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:23:13,502] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.157 seconds
[2022-08-14 18:23:43,618] {processor.py:153} INFO - Started process (PID=11892) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:23:43,619] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:23:43,620] {logging_mixin.py:115} INFO - [2022-08-14 18:23:43,620] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:23:43,692] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:23:43,719] {logging_mixin.py:115} INFO - [2022-08-14 18:23:43,719] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:23:43,740] {logging_mixin.py:115} INFO - [2022-08-14 18:23:43,740] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:23:43,750] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.136 seconds
[2022-08-14 18:24:13,855] {processor.py:153} INFO - Started process (PID=11960) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:24:13,856] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:24:13,857] {logging_mixin.py:115} INFO - [2022-08-14 18:24:13,857] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:24:13,929] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:24:13,959] {logging_mixin.py:115} INFO - [2022-08-14 18:24:13,959] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:24:13,983] {logging_mixin.py:115} INFO - [2022-08-14 18:24:13,983] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:24:13,994] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.143 seconds
[2022-08-14 18:24:44,311] {processor.py:153} INFO - Started process (PID=12037) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:24:44,313] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:24:44,314] {logging_mixin.py:115} INFO - [2022-08-14 18:24:44,314] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:24:44,384] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:24:44,411] {logging_mixin.py:115} INFO - [2022-08-14 18:24:44,411] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:24:44,433] {logging_mixin.py:115} INFO - [2022-08-14 18:24:44,433] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:24:44,445] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.138 seconds
[2022-08-14 18:25:14,712] {processor.py:153} INFO - Started process (PID=12114) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:25:14,713] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:25:14,714] {logging_mixin.py:115} INFO - [2022-08-14 18:25:14,714] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:25:14,796] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:25:14,824] {logging_mixin.py:115} INFO - [2022-08-14 18:25:14,824] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:25:14,849] {logging_mixin.py:115} INFO - [2022-08-14 18:25:14,849] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:25:14,862] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.154 seconds
[2022-08-14 18:25:45,139] {processor.py:153} INFO - Started process (PID=12182) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:25:45,140] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:25:45,141] {logging_mixin.py:115} INFO - [2022-08-14 18:25:45,141] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:25:45,219] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:25:45,254] {logging_mixin.py:115} INFO - [2022-08-14 18:25:45,254] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:25:45,280] {logging_mixin.py:115} INFO - [2022-08-14 18:25:45,280] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:25:45,292] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.157 seconds
[2022-08-14 18:27:58,295] {processor.py:153} INFO - Started process (PID=46) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:27:58,300] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:27:58,302] {logging_mixin.py:115} INFO - [2022-08-14 18:27:58,302] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:27:59,011] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:27:59,049] {logging_mixin.py:115} INFO - [2022-08-14 18:27:59,049] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:27:59,081] {logging_mixin.py:115} INFO - [2022-08-14 18:27:59,081] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:27:59,097] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.807 seconds
[2022-08-14 18:28:29,881] {processor.py:153} INFO - Started process (PID=115) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:28:29,882] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:28:29,883] {logging_mixin.py:115} INFO - [2022-08-14 18:28:29,883] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:28:30,127] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:28:30,155] {logging_mixin.py:115} INFO - [2022-08-14 18:28:30,155] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:28:30,176] {logging_mixin.py:115} INFO - [2022-08-14 18:28:30,175] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:28:30,189] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.312 seconds
[2022-08-14 18:29:01,222] {processor.py:153} INFO - Started process (PID=192) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:29:01,223] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:29:01,224] {logging_mixin.py:115} INFO - [2022-08-14 18:29:01,224] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:29:01,431] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:29:01,453] {logging_mixin.py:115} INFO - [2022-08-14 18:29:01,453] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:29:01,476] {logging_mixin.py:115} INFO - [2022-08-14 18:29:01,476] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:29:01,487] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.269 seconds
[2022-08-14 18:29:31,730] {processor.py:153} INFO - Started process (PID=269) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:29:31,731] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:29:31,732] {logging_mixin.py:115} INFO - [2022-08-14 18:29:31,732] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:29:31,951] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:29:31,980] {logging_mixin.py:115} INFO - [2022-08-14 18:29:31,980] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:29:32,006] {logging_mixin.py:115} INFO - [2022-08-14 18:29:32,006] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:29:32,018] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.292 seconds
[2022-08-14 18:30:02,222] {processor.py:153} INFO - Started process (PID=337) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:30:02,223] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:30:02,224] {logging_mixin.py:115} INFO - [2022-08-14 18:30:02,224] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:30:02,458] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:30:02,488] {logging_mixin.py:115} INFO - [2022-08-14 18:30:02,488] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:30:02,512] {logging_mixin.py:115} INFO - [2022-08-14 18:30:02,512] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:30:02,525] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.307 seconds
[2022-08-14 18:30:32,981] {processor.py:153} INFO - Started process (PID=414) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:30:32,983] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:30:32,984] {logging_mixin.py:115} INFO - [2022-08-14 18:30:32,984] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:30:33,194] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:30:33,218] {logging_mixin.py:115} INFO - [2022-08-14 18:30:33,218] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:30:33,238] {logging_mixin.py:115} INFO - [2022-08-14 18:30:33,238] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:30:33,250] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.273 seconds
[2022-08-14 18:31:03,805] {processor.py:153} INFO - Started process (PID=491) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:31:03,807] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:31:03,808] {logging_mixin.py:115} INFO - [2022-08-14 18:31:03,808] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:31:04,070] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:31:04,093] {logging_mixin.py:115} INFO - [2022-08-14 18:31:04,093] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:31:04,115] {logging_mixin.py:115} INFO - [2022-08-14 18:31:04,115] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:31:04,126] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.325 seconds
[2022-08-14 18:33:28,311] {processor.py:153} INFO - Started process (PID=46) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:33:28,313] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:33:28,315] {logging_mixin.py:115} INFO - [2022-08-14 18:33:28,315] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:33:29,091] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:33:29,131] {logging_mixin.py:115} INFO - [2022-08-14 18:33:29,130] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:33:29,173] {logging_mixin.py:115} INFO - [2022-08-14 18:33:29,172] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:33:29,192] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.889 seconds
[2022-08-14 18:33:59,256] {processor.py:153} INFO - Started process (PID=114) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:33:59,258] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:33:59,260] {logging_mixin.py:115} INFO - [2022-08-14 18:33:59,260] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:33:59,540] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:33:59,572] {logging_mixin.py:115} INFO - [2022-08-14 18:33:59,571] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:33:59,598] {logging_mixin.py:115} INFO - [2022-08-14 18:33:59,598] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:33:59,612] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.361 seconds
[2022-08-14 18:34:30,315] {processor.py:153} INFO - Started process (PID=191) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:34:30,317] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:34:30,319] {logging_mixin.py:115} INFO - [2022-08-14 18:34:30,319] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:34:30,683] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:34:30,713] {logging_mixin.py:115} INFO - [2022-08-14 18:34:30,713] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:34:30,744] {logging_mixin.py:115} INFO - [2022-08-14 18:34:30,743] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:34:30,761] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.451 seconds
[2022-08-14 18:35:01,147] {processor.py:153} INFO - Started process (PID=268) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:35:01,149] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:35:01,151] {logging_mixin.py:115} INFO - [2022-08-14 18:35:01,150] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:35:01,381] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:35:01,407] {logging_mixin.py:115} INFO - [2022-08-14 18:35:01,407] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:35:01,428] {logging_mixin.py:115} INFO - [2022-08-14 18:35:01,428] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:35:01,439] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.296 seconds
[2022-08-14 18:35:32,124] {processor.py:153} INFO - Started process (PID=336) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:35:32,126] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:35:32,127] {logging_mixin.py:115} INFO - [2022-08-14 18:35:32,127] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:35:32,361] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:35:32,384] {logging_mixin.py:115} INFO - [2022-08-14 18:35:32,384] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:35:32,406] {logging_mixin.py:115} INFO - [2022-08-14 18:35:32,406] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:35:32,418] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.298 seconds
[2022-08-14 18:36:02,763] {processor.py:153} INFO - Started process (PID=413) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:36:02,765] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:36:02,766] {logging_mixin.py:115} INFO - [2022-08-14 18:36:02,766] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:36:02,978] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:36:03,001] {logging_mixin.py:115} INFO - [2022-08-14 18:36:03,001] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:36:03,027] {logging_mixin.py:115} INFO - [2022-08-14 18:36:03,027] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:36:03,041] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.282 seconds
[2022-08-14 18:39:14,313] {processor.py:153} INFO - Started process (PID=54) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:39:14,322] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:39:14,328] {logging_mixin.py:115} INFO - [2022-08-14 18:39:14,327] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:39:17,239] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:39:17,563] {logging_mixin.py:115} INFO - [2022-08-14 18:39:17,562] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:39:17,686] {logging_mixin.py:115} INFO - [2022-08-14 18:39:17,685] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:39:17,726] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 3.454 seconds
[2022-08-14 18:39:48,598] {processor.py:153} INFO - Started process (PID=120) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:39:48,604] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:39:48,608] {logging_mixin.py:115} INFO - [2022-08-14 18:39:48,608] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:39:49,309] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:39:49,374] {logging_mixin.py:115} INFO - [2022-08-14 18:39:49,374] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:39:49,452] {logging_mixin.py:115} INFO - [2022-08-14 18:39:49,451] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:39:49,483] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.900 seconds
[2022-08-14 18:40:20,208] {processor.py:153} INFO - Started process (PID=190) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:40:20,210] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:40:20,212] {logging_mixin.py:115} INFO - [2022-08-14 18:40:20,212] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:40:20,535] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:40:20,573] {logging_mixin.py:115} INFO - [2022-08-14 18:40:20,573] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:40:20,609] {logging_mixin.py:115} INFO - [2022-08-14 18:40:20,609] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:40:20,627] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.425 seconds
[2022-08-14 18:40:51,076] {processor.py:153} INFO - Started process (PID=258) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:40:51,078] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:40:51,081] {logging_mixin.py:115} INFO - [2022-08-14 18:40:51,081] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:40:51,389] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:40:51,421] {logging_mixin.py:115} INFO - [2022-08-14 18:40:51,421] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:40:51,453] {logging_mixin.py:115} INFO - [2022-08-14 18:40:51,453] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:40:51,468] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.398 seconds
[2022-08-14 18:41:21,651] {processor.py:153} INFO - Started process (PID=335) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:41:21,653] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:41:21,655] {logging_mixin.py:115} INFO - [2022-08-14 18:41:21,654] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:41:21,964] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:41:21,995] {logging_mixin.py:115} INFO - [2022-08-14 18:41:21,994] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:41:22,029] {logging_mixin.py:115} INFO - [2022-08-14 18:41:22,029] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:41:22,044] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.400 seconds
[2022-08-14 18:41:52,502] {processor.py:153} INFO - Started process (PID=403) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:41:52,504] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:41:52,508] {logging_mixin.py:115} INFO - [2022-08-14 18:41:52,507] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:41:52,847] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:41:52,883] {logging_mixin.py:115} INFO - [2022-08-14 18:41:52,883] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:41:52,916] {logging_mixin.py:115} INFO - [2022-08-14 18:41:52,916] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:41:52,932] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.438 seconds
[2022-08-14 18:42:23,058] {processor.py:153} INFO - Started process (PID=480) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:42:23,061] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:42:23,062] {logging_mixin.py:115} INFO - [2022-08-14 18:42:23,062] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:42:23,364] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:42:23,396] {logging_mixin.py:115} INFO - [2022-08-14 18:42:23,396] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:42:23,427] {logging_mixin.py:115} INFO - [2022-08-14 18:42:23,427] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:42:23,442] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.391 seconds
[2022-08-14 18:42:53,953] {processor.py:153} INFO - Started process (PID=548) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:42:53,955] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:42:53,956] {logging_mixin.py:115} INFO - [2022-08-14 18:42:53,956] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:42:54,195] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:42:54,222] {logging_mixin.py:115} INFO - [2022-08-14 18:42:54,222] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:42:54,246] {logging_mixin.py:115} INFO - [2022-08-14 18:42:54,246] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:42:54,258] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.310 seconds
[2022-08-14 18:43:24,374] {processor.py:153} INFO - Started process (PID=625) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:43:24,377] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:43:24,413] {logging_mixin.py:115} INFO - [2022-08-14 18:43:24,413] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:43:24,705] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:43:24,742] {logging_mixin.py:115} INFO - [2022-08-14 18:43:24,742] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:43:24,782] {logging_mixin.py:115} INFO - [2022-08-14 18:43:24,781] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:43:24,805] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.437 seconds
[2022-08-14 18:43:54,880] {processor.py:153} INFO - Started process (PID=692) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:43:54,882] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:43:54,883] {logging_mixin.py:115} INFO - [2022-08-14 18:43:54,883] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:43:55,115] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:43:55,141] {logging_mixin.py:115} INFO - [2022-08-14 18:43:55,141] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:43:55,165] {logging_mixin.py:115} INFO - [2022-08-14 18:43:55,165] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:43:55,179] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.303 seconds
[2022-08-14 18:44:25,619] {processor.py:153} INFO - Started process (PID=768) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:44:25,621] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:44:25,622] {logging_mixin.py:115} INFO - [2022-08-14 18:44:25,622] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:44:25,885] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:44:25,915] {logging_mixin.py:115} INFO - [2022-08-14 18:44:25,914] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:44:25,942] {logging_mixin.py:115} INFO - [2022-08-14 18:44:25,941] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:44:25,956] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.348 seconds
[2022-08-14 18:44:56,070] {processor.py:153} INFO - Started process (PID=845) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:44:56,072] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:44:56,074] {logging_mixin.py:115} INFO - [2022-08-14 18:44:56,074] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:44:56,353] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:44:56,390] {logging_mixin.py:115} INFO - [2022-08-14 18:44:56,390] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:44:56,424] {logging_mixin.py:115} INFO - [2022-08-14 18:44:56,424] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:44:56,447] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.383 seconds
[2022-08-14 18:45:26,515] {processor.py:153} INFO - Started process (PID=913) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:45:26,516] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:45:26,518] {logging_mixin.py:115} INFO - [2022-08-14 18:45:26,518] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:45:26,760] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:45:26,788] {logging_mixin.py:115} INFO - [2022-08-14 18:45:26,788] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:45:26,817] {logging_mixin.py:115} INFO - [2022-08-14 18:45:26,816] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:45:26,829] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.319 seconds
[2022-08-14 18:45:57,486] {processor.py:153} INFO - Started process (PID=990) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:45:57,488] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:45:57,489] {logging_mixin.py:115} INFO - [2022-08-14 18:45:57,489] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:45:57,718] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:45:57,745] {logging_mixin.py:115} INFO - [2022-08-14 18:45:57,745] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:45:57,771] {logging_mixin.py:115} INFO - [2022-08-14 18:45:57,771] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:45:57,785] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.303 seconds
[2022-08-14 18:46:28,332] {processor.py:153} INFO - Started process (PID=1058) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:46:28,333] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:46:28,334] {logging_mixin.py:115} INFO - [2022-08-14 18:46:28,334] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:46:28,541] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:46:28,563] {logging_mixin.py:115} INFO - [2022-08-14 18:46:28,563] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:46:28,583] {logging_mixin.py:115} INFO - [2022-08-14 18:46:28,583] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:46:28,594] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.267 seconds
[2022-08-14 18:46:58,957] {processor.py:153} INFO - Started process (PID=1135) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:46:58,959] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:46:58,960] {logging_mixin.py:115} INFO - [2022-08-14 18:46:58,960] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:46:59,171] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:46:59,197] {logging_mixin.py:115} INFO - [2022-08-14 18:46:59,197] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:46:59,219] {logging_mixin.py:115} INFO - [2022-08-14 18:46:59,219] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:46:59,229] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.277 seconds
[2022-08-14 18:47:29,794] {processor.py:153} INFO - Started process (PID=1212) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:47:29,796] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:47:29,798] {logging_mixin.py:115} INFO - [2022-08-14 18:47:29,797] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:47:30,011] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:47:30,032] {logging_mixin.py:115} INFO - [2022-08-14 18:47:30,032] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:47:30,051] {logging_mixin.py:115} INFO - [2022-08-14 18:47:30,051] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:47:30,061] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.271 seconds
[2022-08-14 18:51:23,467] {processor.py:153} INFO - Started process (PID=56) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:51:23,469] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 18:51:23,473] {logging_mixin.py:115} INFO - [2022-08-14 18:51:23,472] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:51:24,408] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 18:51:24,464] {logging_mixin.py:115} INFO - [2022-08-14 18:51:24,464] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 18:51:24,534] {logging_mixin.py:115} INFO - [2022-08-14 18:51:24,534] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 18:51:24,563] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 1.109 seconds
[2022-08-14 20:51:40,543] {processor.py:153} INFO - Started process (PID=122) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 20:51:40,586] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 20:51:40,589] {logging_mixin.py:115} INFO - [2022-08-14 20:51:40,589] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 20:51:41,224] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 20:51:41,310] {logging_mixin.py:115} INFO - [2022-08-14 20:51:41,310] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 20:51:41,376] {logging_mixin.py:115} INFO - [2022-08-14 20:51:41,375] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 20:51:41,411] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.874 seconds
[2022-08-14 22:51:56,143] {processor.py:153} INFO - Started process (PID=183) to work on /opt/airflow/dags/spark_job_dag.py
[2022-08-14 22:51:56,145] {processor.py:641} INFO - Processing file /opt/airflow/dags/spark_job_dag.py for tasks to queue
[2022-08-14 22:51:56,146] {logging_mixin.py:115} INFO - [2022-08-14 22:51:56,146] {dagbag.py:507} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 22:51:56,455] {processor.py:651} INFO - DAG(s) dict_keys(['spark_job_dag']) retrieved from /opt/airflow/dags/spark_job_dag.py
[2022-08-14 22:51:56,493] {logging_mixin.py:115} INFO - [2022-08-14 22:51:56,493] {dag.py:2371} INFO - Sync 1 DAGs
[2022-08-14 22:51:56,522] {logging_mixin.py:115} INFO - [2022-08-14 22:51:56,522] {dag.py:2919} INFO - Setting next_dagrun for spark_job_dag to 2022-08-14T18:19:09.951551+00:00, run_after=2022-08-15T18:19:09.951551+00:00
[2022-08-14 22:51:56,534] {processor.py:161} INFO - Processing /opt/airflow/dags/spark_job_dag.py took 0.398 seconds
